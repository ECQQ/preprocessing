{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinct-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pointed-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "contdf = pd.read_csv('../nuevos_datos/dialogues/contributions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "large-camel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54399,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = contdf['text'].values\n",
    "sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seasonal-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(x, test_ptge=0.25, val_ptge=0.25):\n",
    "    size = len(x)\n",
    "    indices = np.arange(0, size)    \n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test = x[: int(size*test_ptge)]\n",
    "    vali = x[int(size*test_ptge):int(size*test_ptge) + int(size*val_ptge)]\n",
    "    train = x[int(size*test_ptge) + int(size*val_ptge):]\n",
    "    \n",
    "    return train, vali, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dominican-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vali, test = train_val_test_split(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "experimental-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "popular-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-interview",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-attempt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-spirit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-binding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
